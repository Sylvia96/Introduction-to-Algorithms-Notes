# 1. Introduction
Sorting -> running example
* Insertion sort 插入排序
* Merge sort 
## 1.1 Algrorithms
*input/output relationship*
### Sorting problem: 
*__Input__: A sequence of n numbers {a1,a2,...,an}.*

*__Output__: A permuation (reordering) {a1',a2',...,an'} of the input sequence such that a1'<=a2'<=...<=an'.*

__e.g.__ input {31,41,59,26,41,58} -> output {26,31,41,41,58,59}

### Insertion sort
*an efficient algotithm for sorting a small number of elements*

*compare A with each one existing*

> 5 __2__ 4 6 1 3

> 2 5 __4__ 6 1 3

> 2 4 5 __6__ 1 3

> 2 4 5 6 __1__ 3

> 1 2 4 5 6 __3__

> 1 2 3 4 5 6

## 1.2 Analyzing algorithms
*computational time*
### Analysis off insertion sort
* size of the input
* same size -> how nearly sorted they already are

*running time <-> size of input*

> Assume: each execution of the ith line takes time ci

> j=2,3,...,n (n=len[A])

> worst-case: T(n) = an^2+bn+c

> *rate of growth (order of growth)*: θ(n^2)

__We usually consider one algorithm to be more efficient than another if its worst-case running time has a lower order of growth.__

## 1.3 Designing algorithms
*divide-and-conquer* -> merge sort
> T(n) = θ(1) if n<=c; aT(n/b)+D(n)+C(n) otherwise.

> A={5,2,4,6,1,3,2,6} -> merge sort

> 5 2 4 6 1 3 2 6

> 25 46 13 26

> 2456 1236

> 12234566

### Analysis of merge sort
__Divide__: *just compute the middle of the subarray -> take constant time* D(n)=θ(1)

__Conquer__: *recursively solve two subproblems -> each of size n/2* 2T(n/2)

__Combine__: *the MERGE procedure on an n-element subarray takes time θ(n)* C(n)=θ(n)

* Mergee sort: T(n)=θ(nlgn) where lgn stands for log2(n)

* For large enough inputs(n), merge sort, with its θ(nlgn) running time, outperforms insertion sort, whose runnning time is θ(n^2), in the worst case.

## 1.4 Summary
> e.g __Insertion sort__: 2n^2 instructions to sort n numbers / __Merge sort__: 50nlgn instructions

> 2x(10^6)^2 instructions/10^8 = 20000s ≈ 5.56hr

> 50x10^6lg10^6 instructions/10^6 = 1000s ≈ 16.67min

* By using an algorithmn whose running time has a lower order of growth, even with a poor compiler, the personal computer runs 20 times faster than the supercomputer!

* Total system performance depends on choosing efficient algorithms as much as on choosing fast hardware.


